{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsolo\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "stopwords = [\"a\", \"about\", \"after\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\",\n",
    "            \"before\", \"being\", \"between\", \"both\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"during\", \"each\",\n",
    "            \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
    "            \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\",\n",
    "            \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"of\",\n",
    "            \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"own\", \"shan't\", \"she\", \"she'd\",\n",
    "            \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\",\n",
    "            \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\",\n",
    "            \"they've\", \"this\", \"those\", \"through\", \"to\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\",\n",
    "            \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "            \"which\", \"while\", \"who\", \"who's\", \"whom\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "            \"your\", \"yours\", \"yourself\", \"yourselves\", \"above\", \"again\", \"against\", \"aren't\", \"below\", \"but\", \"can't\",\n",
    "            \"cannot\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"down\", \"few\", \"hadn't\", \"hasn't\", \"haven't\", \"if\",\n",
    "            \"isn't\", \"mustn't\", \"no\", \"nor\", \"not\", \"off\", \"out\", \"over\", \"shouldn't\", \"same\", \"too\", \"under\", \"why\",\n",
    "            \"why's\", \"won't\", \"wouldn't\"]\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", delimiter = \",\")\n",
    "test = pd.read_csv(\"train.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "no_na_train = train.dropna()\n",
    "no_na_test = test.dropna()\n",
    "non_punctuated_reviews_train = no_na_train['Reviews'].apply(lambda review: review.translate(translator))\n",
    "non_punctuated_reviews_test = no_na_test['Reviews'].apply(lambda review: review.translate(translator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "tokenized_reviews_train = non_punctuated_reviews_train.apply(lambda text: nltk.word_tokenize(text.lower()))\n",
    "tokenized_reviews_test = non_punctuated_reviews_test.apply(lambda text: nltk.word_tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "no_stopwords_reviews_train = [[word for word in tokenized_review if word not in stopwords]\n",
    "          for tokenized_review in tokenized_reviews_train]\n",
    "\n",
    "no_stopwords_reviews_test = [[word for word in tokenized_review if word not in stopwords]\n",
    "          for tokenized_review in tokenized_reviews_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate frequency and remove words occuring less than 5 times\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "for review in tokenized_reviews_train:\n",
    "    for token in review:\n",
    "        frequency[token] += 1\n",
    "\n",
    "reviews = [[token for token in review if frequency[token] > 5]\n",
    "        for review in no_stopwords_reviews_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create id-token dictionary\n",
    "id2word = corpora.Dictionary(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sparse matrix from token dictionary train\n",
    "rows, cols, data = [],[],[]\n",
    "for i, review in enumerate(reviews):\n",
    "    for word in review:\n",
    "        if word in id2word.token2id:\n",
    "            rows.append(i)\n",
    "            cols.append(id2word.token2id[word])\n",
    "            data.append(1)\n",
    "\n",
    "x_train = csr_matrix((data,(rows,cols)), shape=(len(train), len(id2word)))\n",
    "y_train = train.iloc[:, 5]\n",
    "\n",
    "#create sparse matrix from token dictionary test\n",
    "rows, cols, data = [],[],[]\n",
    "for i, review in enumerate(no_stopwords_reviews_test):\n",
    "    for word in review:\n",
    "        if word in id2word.token2id:\n",
    "            rows.append(i)\n",
    "            cols.append(id2word.token2id[word])\n",
    "            data.append(1)\n",
    "\n",
    "x_test = csr_matrix((data,(rows,cols)), shape=(len(test), len(id2word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 5 ... 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 100, random_state = 111)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "predicted = classifier.predict(x_test)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Rating'] = predicted\n",
    "results = test[['Id','Rating']]\n",
    "results.to_csv(\"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
