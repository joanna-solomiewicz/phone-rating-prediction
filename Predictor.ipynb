{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "stopwords = [\"a\", \"about\", \"after\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\",\n",
    "            \"before\", \"being\", \"between\", \"both\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"during\", \"each\",\n",
    "            \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
    "            \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\",\n",
    "            \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"of\",\n",
    "            \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"own\", \"shan't\", \"she\", \"she'd\",\n",
    "            \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\",\n",
    "            \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\",\n",
    "            \"they've\", \"this\", \"those\", \"through\", \"to\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\",\n",
    "            \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "            \"which\", \"while\", \"who\", \"who's\", \"whom\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "            \"your\", \"yours\", \"yourself\", \"yourselves\", \"above\", \"again\", \"against\", \"aren't\", \"below\", \"but\", \"can't\",\n",
    "            \"cannot\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"down\", \"few\", \"hadn't\", \"hasn't\", \"haven't\", \"if\",\n",
    "            \"isn't\", \"mustn't\", \"no\", \"nor\", \"not\", \"off\", \"out\", \"over\", \"shouldn't\", \"same\", \"too\", \"under\", \"why\",\n",
    "            \"why's\", \"won't\", \"wouldn't\"]\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", delimiter = \",\")\n",
    "test = pd.read_csv(\"test.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "no_na_train = train.dropna()\n",
    "no_na_test = test.dropna()\n",
    "non_punctuated_reviews_train = no_na_train['Reviews'].apply(lambda review: review.translate(translator))\n",
    "non_punctuated_reviews_test = no_na_test['Reviews'].apply(lambda review: review.translate(translator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "tokenized_reviews_train = non_punctuated_reviews_train.apply(lambda text: nltk.word_tokenize(text.lower()))\n",
    "tokenized_reviews_test = non_punctuated_reviews_test.apply(lambda text: nltk.word_tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "no_stopwords_reviews_train = [[word for word in tokenized_review if word not in stopwords]\n",
    "          for tokenized_review in tokenized_reviews_train]\n",
    "\n",
    "no_stopwords_reviews_test = [[word for word in tokenized_review if word not in stopwords]\n",
    "          for tokenized_review in tokenized_reviews_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate frequency and remove words occuring less than 5 times\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "for review in tokenized_reviews_train:\n",
    "    for token in review:\n",
    "        frequency[token] += 1\n",
    "\n",
    "reviews = [[token for token in review if frequency[token] > 5]\n",
    "        for review in no_stopwords_reviews_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create id-token dictionary\n",
    "id2word = corpora.Dictionary(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sparse matrix from token dictionary train\n",
    "rows, cols, data = [],[],[]\n",
    "for i, review in enumerate(reviews):\n",
    "    for word in review:\n",
    "        if word in id2word.token2id:\n",
    "            rows.append(i)\n",
    "            cols.append(id2word.token2id[word])\n",
    "            data.append(1)\n",
    "\n",
    "x_train = csr_matrix((data,(rows,cols)), shape=(len(train), len(id2word)))\n",
    "y_train = train.iloc[:, 5]\n",
    "\n",
    "#create sparse matrix from token dictionary test\n",
    "rows, cols, data = [],[],[]\n",
    "for i, review in enumerate(no_stopwords_reviews_test):\n",
    "    for word in review:\n",
    "        if word in id2word.token2id:\n",
    "            rows.append(i)\n",
    "            cols.append(id2word.token2id[word])\n",
    "            data.append(1)\n",
    "\n",
    "x_test = csr_matrix((data,(rows,cols)), shape=(len(test), len(id2word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsolo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  3.1min remaining:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=111, verbose=True,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(random_state = 111, n_jobs = -1, verbose = True)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.6s remaining:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 ... 5 5 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "predicted = classifier.predict(x_test)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Rating'] = predicted\n",
    "results = test[['Id', 'Rating']]\n",
    "results.to_csv(\"results.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
